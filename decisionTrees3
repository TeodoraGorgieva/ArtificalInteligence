from math import log
 
 
def unique_counts(rows):
    """Create counts of possible results (the last column of
   each row is the result)
 
   :param rows: dataset
   :type rows: list
   :return: dictionary of possible classes as keys and count
            as values
   :rtype: dict
   """
    results = {}
    for row in rows:
        # The result is the last column
        r = row[len(row) - 1]
        if r not in results:
            results[r] = 0
        results[r] += 1
    return results
 
 
def gini_impurity(rows):
    """Probability that a randomly placed item will
   be in the wrong category
 
   :param rows: dataset
   :type rows: list
   :return: Gini impurity
   :rtype: float
   """
    total = len(rows)
    counts = unique_counts(rows)
    imp = 0
    for k1 in counts:
        p1 = float(counts[k1]) / total
        for k2 in counts:
            if k1 == k2:
                continue
            p2 = float(counts[k2]) / total
            imp += p1 * p2
    return imp
 
 
def entropy(rows):
    """Entropy is the sum of p(x)log(p(x)) across all
   the different possible results
 
   :param rows: dataset
   :type rows: list
   :return: entropy value
   :rtype: float
   """
    log2 = lambda x: log(x) / log(2)
    results = unique_counts(rows)
    # Now calculate the entropy
    ent = 0.0
    for r in results.keys():
        p = float(results[r]) / len(rows)
        ent = ent - p * log2(p)
    return ent
 
 
class DecisionNode:
    def __init__(self, col=-1, value=None, level=None, results=None, tb=None, fb=None):
        """
       :param col: index of the column (attribute) of the training set that
                   is represented with this instance i.e. this node
       :type col: int
       :param value: the value of the node according to which the partition
                     in the tree is made
       :param results: results for the current branch, value (not None)
                       only in leaves where decision is made.
       :type results: dict
       :param tb: branch that divides from the current node when value is
                  equal to value
       :type tb: DecisionNode
       :param fb: branch that divides from the current node when value is
                  different from value
       :type fb: DecisionNode
       """
        self.col = col
        self.value = value
        self.results = results
        self.tb = tb
        self.fb = fb
        self.level = level
 
 
def compare_numerical(row, column, value):
    """Compare row value of the desired column with particular
   numerical value
 
   :param row: particular row in the set
   :type row: list
   :param column: index of the column (attribute) of the train set
   :type column: int
   :param value: the value of the node according to which the
                 partition in the tree is made
   :type value: int or float
   :return: True if the row >= value, else False
   :rtype: bool
   """
    return row[column] >= value
 
 
def compare_nominal(row, column, value):
    """Compare row value of the desired column with particular
   nominal value
 
   :param row: particular row in the set
   :type row: list
   :param column: index of the column (attribute) of the train set
   :type column: int
   :param value: the value of the node according to which the
                 partition in the tree is made
   :type value: str
   :return: True if the row == value, else False
   :rtype: bool
   """
    return row[column] == value
 
 
def divide_set(rows, column, value):
    """Divides a set on a specific column. Can handle numeric
   or nominal values.
 
   :param rows: the train set
   :type rows: list(list)
   :param column: index of the column (attribute) of the train set
   :type column: int
   :param value: the value of the node according to which the
                 partition in the tree for particular branch is made
   :type value: int or float or string
   :return: divided subsets
   :rtype: list, list
   """
    # Make a function that tells us if a row is in
    # the first group (true) or the second group (false)
    if isinstance(value, int) or isinstance(value, float):
        # if the value for comparison is of type int or float
        split_function = compare_numerical
    else:
        # if the value for comparison is of other type (string)
        split_function = compare_nominal
 
    # Divide the rows into two sets and return them
    # for each row that split_function returns True
    set1 = [row for row in rows if
            split_function(row, column, value)]
    # for each row that split_function returns False
    set2 = [row for row in rows if
            not split_function(row, column, value)]
    return set1, set2
 
 
def build_tree(rows, level, scoref=entropy):
    if len(rows) == 0:
        return DecisionNode()
    current_score = scoref(rows)
 
    # Set up some variables to track the best criteria
    best_gain = 0.0
    best_criteria = None
    best_sets = None
 
    column_count = len(rows[0]) - 1
    for col in range(0, column_count):
        # Generate the list of different values in this column
        column_values = {}
        for row in rows:
            column_values[row[col]] = 1
        # Now try dividing the rows up for each value in this column
        for value in column_values.keys():
            (set1, set2) = divide_set(rows, col, value)
            # Information gain
            p = float(len(set1)) / len(rows)
            gain = current_score - p * scoref(set1) - (1 - p) * scoref(set2)
            if gain > best_gain and len(set1) > 0 and len(set2) > 0:
                best_gain = gain
                best_criteria = (col, value)
                best_sets = (set1, set2)
 
    # Create the subbranches
    if best_gain > 0:
        true_branch = build_tree(best_sets[0], level + 1, scoref)
        false_branch = build_tree(best_sets[1], level + 1, scoref)
        return DecisionNode(col=best_criteria[0], value=best_criteria[1], level=level,
                            tb=true_branch, fb=false_branch)
    else:
        return DecisionNode(results=unique_counts(rows))
 
 
def print_tree(tree, indent=''):
    # Is this a leaf node?
    if tree.results:
        print(str(tree.results))
    else:
        # Print the criteria
        print(str(tree.col) + ':' + str(tree.value) + '? Level=' + str(tree.level))
        # Print the branches
        print(indent + 'T-> ', end='')
        print_tree(tree.tb, indent + '  ')
        print(indent + 'F-> ', end='')
        print_tree(tree.fb, indent + '  ')
 
 
def classify(observation, tree):
    if tree.results:
        return tree.results
    else:
        value = observation[tree.col]
        if isinstance(value, int) or isinstance(value, float):
            compare = compare_numerical
        else:
            compare = compare_nominal
 
        vrednost = tree.value
        if isinstance(vrednost, str):
            vrednost = f'\'{vrednost}\''
        print(f"Sporeduvam kolona i vrednost ({tree.col}, {vrednost})")
        print(f"Tekovna vrednost: {value}")
        if compare(observation, tree.col, tree.value):
            print("Sledna granka: True branch")
            branch = tree.tb
            print("Preostanata granka za izminuvanje:")
            print_tree(branch)
        else:
            print("Sledna granka: False branch")
            branch = tree.fb
            print("Preostanata granka za izminuvanje:")
            print_tree(branch)
 
        print()
        return classify(observation, branch)
 
 
trainingData = [['twitter', 'USA', 'yes', 18, 'None'],
                ['google', 'France', 'yes', 23, 'Premium'],
                ['google', 'France', 'no', 26, 'Basic'],
                ['google', 'Macedonia', 'yes', 13, 'None'],
                ['pinterest', 'USA', 'yes', 24, 'Basic'],
                ['bing', 'France', 'yes', 23, 'Basic'],
                ['google', 'UK', 'no', 21, 'Premium'],
                ['facebook', 'New Zealand', 'no', 12, 'None'],
                ['facebook', 'UK', 'no', 21, 'Basic'],
                ['google', 'USA', 'no', 24, 'Premium'],
                ['twitter', 'France', 'yes', 19, 'None'],
                ['pinterest', 'USA', 'no', 18, 'None'],
                ['google', 'UK', 'no', 18, 'None'],
                ['bing', 'UK', 'yes', 19, 'Premium'],
                ['bing', 'Macedonia', 'no', 10, 'None'],
                ['facebook', 'Macedonia', 'no', 16, 'Basic'],
                ['bing', 'UK', 'no', 19, 'Basic'],
                ['pinterest', 'Germany', 'no', 2, 'None'],
                ['pinterest', 'USA', 'yes', 12, 'Basic'],
                ['twitter', 'UK', 'no', 21, 'None'],
                ['twitter', 'UK', 'yes', 26, 'Premium'],
                ['google', 'UK', 'yes', 18, 'Basic'],
                ['bing', 'France', 'yes', 19, 'Basic']]
 
if __name__ == "__main__":
    referrer = input()
    location = input()
    readFAQ = input()
    pagesVisited = int(input())
    serviceChosen = 'Unknown'
 
    testCase = [referrer, location, readFAQ, pagesVisited, serviceChosen]
 
    tree = build_tree(trainingData, 0)
    print_tree(tree)
    classification = list(classify(testCase, tree))[0]
    print(classification)
